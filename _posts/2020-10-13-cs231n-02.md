---
title: "[CS231n] Lecture 2 - Image Classification Pipeline"
date: 2020-10-13
categories: dl
toc: true
toc_sticky: true
toc_label: "목차"
tags : data dl datastudy cs231n
related: true
header:
  teaser: "https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/teasers/cs231n.png?raw=true"
---



<img src= "https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/teasers/cs231n.png?raw=true">

스탠포드 대학의 CS231n 강의노트입니다. 

CS231n강의는 1~16강으로 구성되어 있으며 이번 포스트는 **Lecture 2 - Image Classification Pipeline** 에 대해 다루겠습니다.

*가짜연구소*의 *딥러닝 이론 스터디* 활동으로 작성되었습니다.

- youtube 강의 영상 바로가기 [링크](https://youtu.be/vT1JzLTH4G4?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk)
- 가짜연구소 사이트 바로가기 [링크](https://pseudo-lab.com/)

<center><p>
  <img src="https://visitor-badge.laobi.icu/badge?page_id=jihyun22.github.io/dl/cs231n-02/" alt="visitor"/>
    </p></center>




---

<br/>



# 🚀 **개요** 

---

<br/>

2강에서는 이미지 분류에 대해 다룹니다. 

이미지 분류는 컴퓨터 비전에서 가장 중요한 작업입니다. 

<br/>



---

## 컴퓨터가 사진을 보는 법

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/1.jpg?raw=true)

컴퓨터는 사진 입력에 대해 RGB 값을 기준으로 한 숫자들의 나열로 인식합니다.

사진을 찍는 각도에 따라 이러한 RGB 값이 바뀌기 때문에, 사람에 비해 사진을 인식하는 속도가 느릴 수 밖에 없습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/2.jpg?raw=true)

위 슬라이드처럼, 같은 고양이더라도 RGB 값이 천차만별로 달라지기 때문에 인식에 더욱 어려움이 발생합니다.



이러한 문제를 극복하기 위해 새롭게 등장한 아이디어는 데이터에 기반한 접근법입니다. 

사진을 단순히 인식하는 코드가 아닌, 동일한 카테고리의 수많은 사진들을 input으로 주어진 후 라벨을 먼저 구하는 방식입니다.

<br/>

## Nearest Neighbor

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/3.jpg?raw=true)

처음 등장한 분류법은 Nearest Neighbor 입니다.

input으로 주어진 데이터를 모두 저장하고 새로운 input 사진에 대해 기존 데이터와 비교하며 가장 비슷하게 생긴 input을 찾아내는 방식입니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/4.jpg?raw=true)

사용된 데이터 셋은 CIFAR-10 입니다. 

이 데이터셋은 총 10가지 종류의 물체와 동물을 모아둔 사진 묶음입니다. 이 데이터셋을 기반으로 학습을 시작합니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/5.jpg?raw=true)

분류 방법은 이름처럼 직관적입니다.

학습 방법은 다음과 같습니다.

- 컴퓨터가 인식하는 이미지, 즉 숫자들의 나열에 대해서 숫자 간 크기를 비교합니다.

- 비교 대상의 이미지 간 숫자들을 모두 빼고 절대값을 씌워 두 숫자 사이의 거리 L1을 연산합니다.

- 모든 픽셀에 대해 동일한 연산을 수행하면 하나의 결과값을 도출할 수 있습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/6.jpg?raw=true)

예측 방법도 단순합니다.

기존 학습한 데이터셋을 기준으로 새로운 input데이터의 숫자 배열을 빼고, 해당 결과를 바탕으로 가장 유사하다고 판단되는 카테고리를 결과값으로 도출합니다.

즉, 강아지 사진 카테고리와 비교했을 때 평균 100정도 차이가 나고, 고양이 사진 카테고리와 비교했을 때에는 평균 200정도 차이가 난다면, 이 사진은 강아지에 가깝다고 판단하는 방식입니다.

이 방법의 가장 큰 문제는 학습 시간의 비효율성입니다.

모든 사진에 대해 뺄셈 연산을 하고 평균값을 계산하는 과정은 상당히 많은 연산이 필요합니다.

학습 시간을 제외하고도 예측 과정에서 소요되는 시간은 무시할 수 없을 정도로 상당합니다.

<br/>

## K-Nearest Neighbor

<br/>

K-Nearest Neighbor 방법은 기존 Nearest Neighbor 방법의 단점을 보완하기 위해 등장했습니다.

가장 가까운 사진을 찾는다는 기본 아이디어는 동일하지만, 주변 사진을 비교하였을 때 가장 비슷한 것이 정답일 가능성이 높다는 해법이 추가된 방법입니다.

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/7.jpg?raw=true)

<br/>

이 방법으로 CIFAR-10 데이터셋을 훈련시킨 결과는 다음과 같습니다.

<br/>

## Linear Classification

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/8.jpg?raw=true)

Linear Classification, 선형 분류 방법은 가중치의 개념을 반영하여 분류 작업을 수행합니다.

이미지가 32 * 32 * 3 개의 숫자들로 이루어져 있을 때, 가중치 변수를 함수에 추가하여 10개의 카테고리에 대한 점수를 계산합니다.

이 방법은 매개 변수적 접근 방식으로 기존 Nearest Neighbor 에 비해 훨씬 더 빠르게 예측이 가능합니다.



가장 기본적인 형태인 함수가 f(x, W) = W * x + b 라 하겠습니다.

- W * x 연산
  - 이때 x는 이미지를 1차원 배열로 3072 * 1 숫자 배열로 변형한 값 입니다.
  - 새로운 배열 3072 * 10을 생성한 후 W로 사용하겠습니다.
  - W의 첫 줄과 x를 곱하고, 두번째 줄과 x를 곱하는 연산을 반복하여 10개의 숫자를 구할 수 있습니다.

- +b 연산
  - 카테고리 각각의 점수를 구하기 위해 b = 1 * 10 의 크기로 초기화합니다.
  - 이러한 b 값은 편향 값 입니다.(bias)
  - 이미지의 라벨의 불균형성을 보완하기 위한 값 입니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/9.jpg?raw=true)

다음 이미지의 분류 결과를 예시로 살펴보겠습니다.

좌표 평면 위 일차 함수의 직선을 기준으로 각각 비행기, 사슴, 자동차 등으로 이미지를 분류하는 것을 확인할 수 있습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/10.jpg?raw=true)

그러나 문제점도 발생합니다. 일차함수 직선으로 정확히 분류되지 않는 다음과 같은 경우, 완벽한 결과값을 얻기엔 어렵습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-2/11.jpg?raw=true)

이러한 어려움을 보완하기 위해 W 가중치 개념이 필요합니다. 

<br/>

# **📗 정리**

---

 <br/>

지금까지 선형 분류의 개념을 바탕으로 이미지 분류의 기본적인 방법을 살펴보았습니다. 

이어지는 게시물에서는 최적의 W 값을 찾는 방법에 대해 다루겠습니다.

 <br/>


