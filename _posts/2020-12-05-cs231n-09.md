---
title: "[CS231n] Lecture 9 - CNN Architectures"
date: 2020-12-05
categories: dl
toc: true
toc_sticky: true
toc_label: "목차"
tags : data dl datastudy cs231n
related: true
header:
  teaser: "https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/teasers/cs231n.png?raw=true"
---



<img src= "https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/teasers/cs231n.png?raw=true">

스탠포드 대학의 CS231n 강의노트입니다. 

CS231n강의는 1~16강으로 구성되어 있으며 이번 포스트는 **Lecture 9 - CNN Architectures** 에 대해 다루겠습니다.

*가짜연구소*의 *딥러닝 이론 스터디* 활동으로 작성되었습니다.

- youtube 강의 영상 바로가기 [링크](https://youtu.be/vT1JzLTH4G4?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk)
- 가짜연구소 사이트 바로가기 [링크](https://pseudo-lab.com/)

<center><p>
  <img src="https://visitor-badge.laobi.icu/badge?page_id=jihyun22.github.io/dl/cs231n-09/" alt="visitor"/>
    </p></center>








---

<br/>



# 🚀 **개요** 

---

<br/>

9강은 현재까지 공부한 CNN모델, AlexNet, googLeNet 등을 소개하고 있습니다.

CNN의 구조를 살펴보고 각 모델의 구조적 특징을 공부하겠습니다.

<br/>



---

## LeNet ~ AlexNet

---

CNN 모델의 역사는 leNet 부터 시작합니다. 1998년 연구가 시작되어 Convolutions Net 개념이 처음 적용된 모델이 LeNet 입니다.

이후 2012년, AlexNet(알렉스넷) 이 등장하면서 오차율이 급격하게 줄어들게 됩니다. AlexNet을 전환점으로 CNN 모델이 상당히 발전하게 되었습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-9/009.jpg?raw=true)

<br/>

알렉스넷은 Convolution layer, max pool, 정규화 순서로 구성되어 있습니다.

이중 정규화 층은 현재 사용되지 않는 net 입니다. 

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-9/011.jpg?raw=true)

<br/>

알렉스넷의 input dim와 output dim 을 살펴보겠습니다.

227\*227\*3 크기의 input 이 위 슬라이드의 모델을 통과하게 되면

1. conv1 필터가 11*11, stride=4
2. 따라서 (227-11) / 4 =55
3. 총 96개의 필터가 있으므로 55\*55\*96

위 연산을 통해 output 크기는 55\*55\*96이 됩니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-9/012.jpg?raw=true)

<br/>

파라미터의 개수는 11\*11\*3\*96 = 34848 입니다.

11*11 의 필터가 3차원으로 구성되어 있으며 총 필터 개수는 96개 이기 때문입니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-9/013.jpg?raw=true)

<br/>

이때 2번째 layer의 output volumn size를 계산하겠습니다.

1. 2번째 레이어는 풀링 레이어
2. 첫번째 레이어에서 55의 사이즈의 input이 입력됨
3. 필터의 크기가 3*3으로 설정
4. stride = 2
5. (55-3)/2 + 1 = 27
6. 따라서 27 \* 27 \* 96

위 연산의 순서대로 output volume size는 27 \* 27 \* 96 으로 계산됩니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-9/015.jpg?raw=true)

<br/>

단, 이 레이어에서 파라미터 개수는 0입니다.

이처럼 풀링 레이어는 단순히 input을 압축하는 등 size측면의 역할을 수행하기 때문에 파라미터를 사용하지 않습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-9/018.jpg?raw=true)

<br/>

이러한 순서로 전체 레이어의 output 사이즈 등을 계산하면 위와 같은 결과를 얻을 수 있습니다.

알렉스넷의 특징을 정리하면 다음과 같습니다.

1. ReLU 활성화 함수를 처음으로 사용했습니다.
2. data augmetation을 사용했습니다. (flipping, jittering, color norm 등)
3. dropout을 사용했습니다.
4. batch 방법을 적용했습니다.
5. lr를 le-2~le-10으로 조정했습니다.
6. weight decay를 사용하여 regularization 방법을 사용했습니다. 가중치 값이 증가하는 것을 제한하여 모델의 복잡도를 안정적으로 제한했습니다.
7. 앙상블 방법을 사용했습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-9/023.jpg?raw=true)

<br/>

알렉스넷은 2012년 imagenet 에서 우승을 한 최초의 CNN 기반 우승 모델로 지금의 CNN모델이 만들어질 수 있었던  초석입니다.

<br/>

---

## ZFNet ~ VGGNet

---



![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-7/29.jpg?raw=true)

<br/>

기존의 FC Layer가 입력 이미지를 1차원 벡터로 변형시켜 연산을 진행했다면, 이제는 기존의 이미지 구조를 그대로 유지하여 input 입력 데이터로 사용합니다.

이후 위 슬라이드에서 filter 라는 가중치 벡터를 통과해서 내적 연산을 수행합니다. 

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-7/31.jpg?raw=true)

<br/>

이때 원본 데이터의 깊이, 3은 전체를 취하지만, 32* 32 중 filter 의 크기인 5*5만 취해서 해당 이미지의 픽셀을 곱해줍니다. 

물론, 각 벡터 간 convolution 을 하거나, 이미지를 1차원으로 펼쳐 내적 연산을 수행하는 것과 동일한 연산입니다.

결과값은 필터당 1개로, 여러개의 필터를 사용하면 여러 activation map을 얻을 수 있습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-7/36.jpg?raw=true)

<br/>

각 레이어의 출력은 다음 layer의 입력이 됩니다.

이때 pooling은 activation maps의 사이즈를 줄이는 역할을 수행합니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-7/37.jpg?raw=true)

필터를 많이 통과할수록, 즉 layer의 계층이 높아질 수록 더 많은 특징을 담아낼 수 있습니다.

<br/>

---

## GoogLeNet ~ ResNet

---

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-7/47.jpg?raw=true)

<br/>

다음은 stride의 개념을 알아보겠습니다.

stride는 한 칸씩 움직이는 정도를 의미하며, 이때 stride가 input 이미지에 맞지 않으면 불균형한 결과를 부를 수도 있습니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-7/52.jpg?raw=true)

<br/>

따라서 해당 필터를 통과하면 얻을 수 있는 output 사이즈는 (input size-filter) / stride +1 입니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-7/53.jpg?raw=true)

<br/>

추가로, Zero-padding은 가장자리의 필터 연산을 수행하여 입력의 사이즈를 유지하는 역할을 수행합니다. 위와 같은 연산을 수행하면 새 출력이 7*7이 되며 출력의 차원이 입력의 차원과 같아지게 됩니다.

이때, Zero-padding을 하지 않으면, Layer가 쌓이면서 output 사이즈가 급격히 줄어들게 돕니다. 이러한 결과는 activation map이 작아지기 때문에 바람직한 결과가 아닙니다.

<br/>

![](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/cs231n-7/60.jpg?raw=true)

실제 계산을 진행하면 위와 같이 계산되며 최종, 파라미터의 개수는 760입니다.



<br/>

---



# **📗 정리**

---

 <br/>

지금까지 CNN의 발전 과정과 모델별 구조를 살펴봤습니다.

다음 강의에서는 이러한 구조적 특징을 고려한 CNN의 파라미터에 대해 알아보겠습니다.

 <br/>


