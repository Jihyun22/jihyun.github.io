---
title: "[데이콘 원자력발전소 대회 리뷰] 탐색적 데이터 분석(EDA)"
date: 2020-06-27
categories: 데이콘리뷰
toc: true
toc_sticky: true
toc_label: "목차"
tags : 원자력발전소상태판단 EDA 데이터분석 DACON ML 머신러닝 
---
<p>
  <img src="https://visitor-badge.laobi.icu/badge?page_id=jihyun22.github.io/dacon/ect/nuclear-02/" alt="visitor"/>
</p>


## 불균형한 데이터 분포, 어떻게 처리해야 할까?

지난 6월부터 7월 중순까지 약 4주간에 걸쳐 Dacon 원자력 상태판단대회 온라인 스터디(2기)가 진행되었습니다. 스터디에서 진행한 내용을 보다 많은 분들과 고민하고자 앞으로 4차례에 걸쳐 코드공유 게시물을 업로드할 예정입니다.

온라인 스터디와 관련한 자료는 아래 링크를 참조해 주세요.

- 데이콘 온라인 스터디 커리큘럼 [바로가기](https://www.dropbox.com/scl/fi/eaxxhf0pudm9jvckqgf4k/.papert?dl=0&rlkey=yqyrpk9eluqauoi5xjmywmp66)
- 1주차 세션 진행 자료 [바로가기](https://www.dropbox.com/scl/fi/hj22v4f47ythje8flvvm2/1.paper?dl=0&rlkey=0mrorfzb3hnvauscl459gl50z)
- 2주차 세션 진행 자료 [바로가기](https://www.dropbox.com/scl/fi/qezpyfkbj0om86afkk3bs/2.paper?dl=0&rlkey=i4nysx05x2tgy26mlkpu6cdhm)

------

두번째 주제는 <불균형한 데이터 분포, 어떻게 처리해야 할까?>로, 데이터의 분포도를 살펴보고 데이터 분포의 불균형이 초래할 수 있는 문제와 리샘플링 방법에 대해 다뤄보고자 합니다.

이전 첫번째 주제와 이어지는 게시물입니다.

- [데이콘 온라인 스터디] 1주차 - 칼럼을 2천개나 줄였습니다! 게시물 [바로가기](https://dacon.io/competitions/official/235551/codeshare/1371?page=1&dtype=recent&ptype=pub)

*(이하 내용은 원자력 온라인 스터디 1, 2기에서 다루었던 내용이 포함되어 있습니다.)*

-----

### 3. 데이터 분포

라벨 별 데이터의 분포를 통해 데이터 분포를 살펴보겠습니다. 우선 데이터를 로드하겠습니다. 방식은 이전 게시물과 동일합니다.


```python
import multiprocessing 
from multiprocessing import Pool 
from functools import partial 
from data_loader_v2 import data_loader_v2
import os 
import pandas as pd
import numpy as np
import joblib
```


```python
train_folder = 'train/'
train_list = os.listdir(train_folder)
train_label_path = 'train_label.csv'
train_label = pd.read_csv(train_label_path, index_col=0)
```


```python
def data_loader_all_v2(func, files, folder='', train_label=None, event_time=15, nrows=75):   
    func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)  
    if __name__ == '__main__':
        pool = Pool(processes=multiprocessing.cpu_count()) 
        df_list = list(pool.imap(func_fixed, files)) 
        pool.close() 
        pool.join() 
    combined_df = pd.concat(df_list)
    return combined_df
```


```python
# event_time=15, nrows=75 설정
train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, train_label=train_label, event_time=15, nrows=75)
```


```python
# 의미 없는 칼럼 드랍(첫번째 게시물 참조)
train = train.loc[:,train.std()!=0]
X_train = train.drop(['label'], axis=1)
y_train = train['label']
```

라벨별 파일 할당을 시각화하여 확인해보겠습니다.


```python
import matplotlib.pyplot as plt
import seaborn as sns
import sys
import warnings
```


```python
#라벨 별 분포도
warnings.filterwarnings(action='ignore')
plt.figure(figsize=(20, 50))
sns.countplot(y=y_train)
plt.title('N of data allocation by label \n', size=20)
plt.grid()

plt.show()
```


![png](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/2020-06-27-nuclear-02/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B%20%EB%B6%84%ED%8F%AC%EB%8F%84.png?raw=true)


110라벨의 경우 약 24여개의 데이터가 포함된 반면 일부 라벨은 1개의 데이터만 포함된 경우도 더러 있습니다. 데이터의 불균형한 분포가 부적절하다고 판단하여 균형을 맞출 수 있도록 **리샘플링을 진행**하는 것으로 결정했습니다.

불균형한 데이터 문제를 해결하기 위해서는 분류 알고리즘 자체의 성능을 향상시키거나, 리샘플링하여 균형을 맞추는 방법이 고려됩니다. 리샘플링을 위해서는 데이터셋 내에서 상대적으로 다수를 차지하는 클래스의 비중을 낮추기 위해 1) 적은 클래스의 비중을 높이거나(**Over-Sampling**), 2) 다수를 차지하는 클래스를 줄이는 방법(**Under-Sampling**)등이 있습니다.

-----

### 4. 데이터 리샘플링

데이터를 리샘플링 하는 방법에 대해서는 다양한 논의가 이루어졌습니다. 2안으로 나누어 설명하겠습니다.

#### <1안. Under-Sampling>

**라벨 별 데이터를 최소값인 1개로 재 할당**하는 방법입니다. train_label에서 라벨의 중복값을 제거한 id를 사용한다면 데이터의 할당 개수를 맞출 수 있습니다.

이때 기존 데이터 셋 크기에 비해 적은 양의 데이터셋이 구성되는데, 이를 보완하고자 nrows변수를 베이스라인 기준 60에서 300으로 임의 확장하여 부족한 데이터 보충할 수 있도록 구성하였습니다.

그러나 라벨 별 할당한 데이터가 과연 해당 라벨을 대표할 수 있는지 한계가 있습니다. 따라서 대표값을 논리적으로 산정할 수 있도록 분산 분석으로 전제를 확인해야 할 필요가 있습니다.

대표값 산정을 위한 분석을 진행하였으나, 어떤 데이터가 대표성을 띄는지 결론을 내기 어려웠습니다. 이 점도 조금 더 고민해서 좋은 결과가 있으면 추가로 공유하도록 하겠습니다.



#### <2안. Over-Sampling>

**라벨 별 데이터를 최대값인 24개로 재 할당**하는 방법입니다. 각 train 데이터가 완전히 상태 B인 이후 time(15~)에서 데이터 임의 분할(예. 15-75, 75-135, … ~599)하여 구성된 데이터 묶음을 기준으로 라벨 별 데이터를 할당한다면 적은 클래스를 효과적으로 확장할 수 있습니다.

라벨에 1개의 id의 데이터만 포함되더라도 부족한 데이터를 보충할 수 있어 불균형을 해소할 수 있으나, 그러나 시간(row)이 데이터 값에 큰 영향을 미칠 수 있다는 한계가 있습니다. 따라서 데이터의 임의 분할 과정에서 row값에 크게 영향을 받지 않는다는 전제를 확인할 필요가 있습니다.



이 중 1안인 Under-Sampling 방식을 채택하여 리샘플링을 진행하였으며 결과는 다음과 같습니다.




```python
# Under-Sampling - label 별 1개의 파일 할당
sample_list = list(train_label.drop_duplicates().index)
train_list = [f'{i}.csv' for i in sample_list]
```


```python
# event_time, nrows 변수 조정
# event_time = 15, nrows = 200
def data_loader_all_v2(func, files, folder='', train_label=None, event_time=15, nrows=200):
    func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)     
    if __name__ == '__main__':
        pool = Pool(processes=multiprocessing.cpu_count()) 
        df_list = list(pool.imap(func_fixed, files)) 
        pool.close()
        pool.join()        
    combined_df = pd.concat(df_list)    
    return combined_df
```


```python
# train_list 반영하여 새로운 train 셋 구성
train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, train_label=train_label)
```


```python
train = train.loc[:, train.std() != 0]
```


```python
X_train = train.drop(['label'], axis=1)
y_train = train['label']
```


```python
X_train.shape, y_train.shape
```




    ((36630, 3455), (36630,))



데이터를 불러온 후, Under-Sampling 을 하여 데이터 개수 최소값인 1에 맞춰 임의로 1개의 id만 할당한 결과입니다. 성능 저하의 폭만 확인하기 위해 할당한 id는 데이터 묶음의 첫 id로 배정했습니다. (예. 110라벨에 대한 id가 18, 26, 112, 115, 190 ... 일 때 18만 할당하고 나머지 데이터는 제거)

라벨별 데이터 분포도를 시각화하여 살펴보겠습니다. 


```python
import matplotlib.pyplot as plt
import seaborn as sns
import sys
import warnings
```


```python
#리샘플링 결과 라벨 별 분포도
plt.figure(figsize=(20, 50))
sns.countplot(y=y_train)

plt.title('N of data allocation by label_Resampling\n', size=20)
plt.grid()
plt.show()
```


![png](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/2020-06-27-nuclear-02/%EB%A6%AC%EC%83%98%ED%94%8C%EB%A7%81%20%ED%9B%84%20%EB%B6%84%ED%8F%AC%EB%8F%84.png?raw=true)


리샘플링 결과의 성능 평가를 위해 단순 rf 모델을 사용하여 원본 데이터 결과와 비교해 보았습니다. 원본 데이터의 결과는 첫번째 게시물 또는 아래 결과 화면 사진을 참고해 주세요.

![rf결과](https://github.com/Jihyun22/Jihyun22.github.io/blob/master/_posts/images/2020-06-27-nuclear-02/%EC%B0%B8%EA%B3%A0%EC%9E%90%EB%A3%8C.jpg?raw=true)


```python
#리샘플링 성능평가
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

rcf_3=RandomForestClassifier(n_estimators=300)
scores = cross_val_score(rcf_3, X_train, y_train, scoring='accuracy', cv=3)
print('CV3인 경우 개별 fold 세트별 정확도 : ', scores)
print('평균 정확도 : {0:.4f}'.format(np.mean(scores)))
```

    CV3인 경우 개별 fold 세트별 정확도 :  [0.76764947 0.84987715 0.75438165]
    평균 정확도 : 0.7906


리샘플링한 데이터의 rf결과는 평균 정확도 0.7906 정도로 원본 데이터와 큰 차이가 나지 않았습니다. 임의로 파일 id를 배정하였음에도 성능 저하의 폭이 크지 않다는 점을 고려한다면, 랜덤하게 id를 배정하거나 분산 분석을 통해 대표값을 할당한다면 훨씬 더 높은 정확도를 얻을 수 있을 것으로 예상합니다. 

대표값을 산정하기 위해 여러 분산 분석 기법을 적용하였지만, 신뢰도가 높은 결과를 얻지 못했습니다. 관련 부분에 대해서는 조금 더 고민해보고자 합니다.

다음 게시물에서는 데이터의 차원 분석을 진행하여 경향성을 파악하고 이상치를 제거했던 과정을 소개하겠습니다.

---



---

<center> <BIG>[데이콘리뷰] 관련 목록 바로가기 </BIG> </center>

---



